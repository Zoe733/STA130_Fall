{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c926b79",
   "metadata": {},
   "source": [
    "#  Pre-lecture homework Answer of question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2c2da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff749802",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbb24d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364a9bd",
   "metadata": {},
   "source": [
    "observations: These are the individual entries or rows in the DataFrame. Each observation typically represents a single data point, entity, or case, and it is indexed by the rows. In the DataFrame I am using, each observation would correspond to a row that potentially represents a villager, assuming the data is about individuals.\n",
    "\n",
    "Variables: These are the different attributes or features that describe each observation, and they are indexed by the columns in my DataFrame. Each variable represents a type of information that is collected about the observations. For example, in the case above, variables might include attributes like name, gender, species, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c26081",
   "metadata": {},
   "source": [
    "# Question3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed9d80d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87149c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male      204\n",
       "female    187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeaea1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personality\n",
       "lazy      60\n",
       "normal    59\n",
       "cranky    55\n",
       "snooty    55\n",
       "jock      55\n",
       "peppy     49\n",
       "smug      34\n",
       "uchi      24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['personality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74f9f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "birthday\n",
       "1-27     2\n",
       "12-5     2\n",
       "7-31     2\n",
       "3-26     2\n",
       "8-3      2\n",
       "        ..\n",
       "4-3      1\n",
       "10-26    1\n",
       "7-23     1\n",
       "12-8     1\n",
       "3-8      1\n",
       "Name: count, Length: 361, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['birthday'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31eea70",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7661f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211addfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db77e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91033d",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1c8b5",
   "metadata": {},
   "source": [
    "df.shape: Purpose: df.shape is an attribute of the DataFrame that returns a tuple reflecting its dimensions, specifically the number of rows and columns it contains. Output: The output is a tuple where the first element represents the number of rows and the second represents the number of columns, formatted as (number_of_rows, number_of_columns). Use Case: Employ df.shape for a quick assessment of the size of my dataset, including the total number of entries and the number of attributes each entry has.\n",
    "\n",
    "df.describe(): Purpose: This function generates summary statistics relevant to the DataFrame columns. For numeric data, it yields metrics like mean, standard deviation, and quartiles, and it can also summarize categorical data to show unique counts, the most common category, and its frequency. Output: The output is a DataFrame where each row corresponds to a different statistic and each column corresponds to a numerical (or specified categorical) column from the original DataFrame. Use Case: Utilize df.describe() to examine the statistical properties of numeric data and the composition of categorical variables within my dataset, providing insights into the distribution, variation, and central tendencies of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90c362",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4184f6",
   "metadata": {},
   "source": [
    "count: The number of non-null entries in the column. This indicates how many data points are available for that variable, which is important for assessing sample size and missing data.\n",
    "\n",
    "Mean (Average Value): The average of all non-null values in the column. It is calculated by summing up all the values and dividing by the count of values. The mean provides a measure of the central tendency of the data.\n",
    "\n",
    "Standard Deviation: A measure of the amount of variation or dispersion in a set of values. A low standard deviation means that the values tend to be close to the mean, while a high standard deviation means that the values are spread out over a wider range.\n",
    "\n",
    "Min (Minimum): The smallest value in the column. This gives an idea of the lower bound of the data range.\n",
    "\n",
    "First Quartile (25%): Also known as the lower quartile, it is the median of the data values below the median in a dataset. Essentially, 25% of the data points are less than or equal to this value.\n",
    "\n",
    "Median (50%): The middle value of the dataset when it is ordered from least to greatest. If the dataset has an even number of observations, the median is the average of the two middle numbers. This is a better measure of central tendency when the data is skewed because it is less affected by outliers and extreme values.\n",
    "\n",
    "Third Quartile (75%): Also known as the upper quartile, it is the median of the data values above the median in a dataset. This means that 75% of the data points are less than or equal to this value.\n",
    "\n",
    "Max (Maximum): The largest value in the column. This gives an idea of the upper bound of the data range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c295f",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa748e0",
   "metadata": {},
   "source": [
    "Missing \"Across Rows\"\n",
    "When data is missing \"across rows,\" it means that certain observations (rows) have missing values in one or more columns. This pattern might indicate specific instances where data collection failed or where certain conditions led to incomplete data entries.\n",
    "\n",
    "Handling Method: df.dropna():\n",
    "This method is used to drop rows that contain any or all missing values, depending on the parameters set. The default behavior (df.dropna()) removes any row containing at least one missing value.\n",
    "Use when: You want to ensure that analyses or models are only built with completely observed cases, or when the number of rows with missing data is small enough that their removal doesn't significantly reduce the dataset's size or representativeness.\n",
    "Missing \"Down Columns\"\n",
    "When data is missing \"down columns,\" it indicates that an entire feature (column) has missing values, either completely or to a significant extent. This might happen if a particular measurement was difficult to obtain or irrelevant for a subset of observations.\n",
    "\n",
    "Handling Method: del df['col'] or df.drop('col', axis=1):\n",
    "These methods are used to remove a specific column from the DataFrame. The del statement removes the column in-place, while df.drop() can be configured to operate in-place or return a modified copy of the DataFrame.\n",
    "Use when: A significant portion of a column is missing, which could bias any analysis including it, or when the column isn't relevant to your analysis/questions.\n",
    "Deciding Between the Two\n",
    "The choice between dropping rows or columns generally comes down to the nature of the missing data and the goals of your analysis:\n",
    "\n",
    "Drop rows if the loss of data points doesn't significantly impact the dataset's integrity or if complete cases are necessary for a particular analysis.\n",
    "Drop columns if the missing data is extensive within a column and imputation isn't feasible or would introduce significant bias, or if the column isn't crucial for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a88c0",
   "metadata": {},
   "source": [
    "#example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84307125",
   "metadata": {},
   "source": [
    "#example of using df.dropna() might be peferred over using del df['col']\n",
    "scenario: When having a data set of customer transactions where some transactions are missing the purchase_amount but have other important details like customer_id and transaction_date.\n",
    "\n",
    "Reason to Use df.dropna(): If you want to analyze the total revenue and only care about transactions where the purchase_amount is available, you might prefer to drop rows with missing purchase_amount values. This is because keeping rows with missing purchase_amount would result in incomplete analysis or inaccurate results.\n",
    "\n",
    "The code is written as\n",
    "cleaned_df = df.dropna(subset=['purchase_amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22965ab1",
   "metadata": {},
   "source": [
    "#example of using del df['col'] might be preferred over using df.dropna()\n",
    "scenario: When having a dataset of employee records, but the temporary_address column has a lot of missing data and is not essential for analysis focusing on permanent addresses and employment history.\n",
    "\n",
    "Reason to Use del df['col']: If the column is largely empty and irrelevant for your analysis, it might be more efficient to remove the column entirely. This avoids the need to handle missing values within the column and simplifies the dataset.\n",
    "\n",
    "The code is written as\n",
    "del df['temporary_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf370957",
   "metadata": {},
   "source": [
    "#example of why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "importance: Applying del df['col'] before df.dropna() can be important if a column contains a high proportion of missing data and is not relevant for analysis. Removing such columns first reduces the complexity of the dataset and avoids unnecessary operations.For example, if having a column with 90% missing data, dropping rows based on that column might lead to losing a significant portion of dataset. By removing the column first, focusing  df.dropna() on the more relevant columns and retain a larger portion of your dataset.\n",
    "\n",
    "The code is written as\n",
    "del df['irrelevant_column']\n",
    "\n",
    "Then drop rows with missing values in the remaining columns\n",
    "cleaned_df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08fd2a0",
   "metadata": {},
   "source": [
    "#example of Removing Missing Data and Justification\n",
    "dataset:assuming a dataset with columns ['A', 'B', 'C', 'D'], where column A has a lot of missing values, and columns B, C, and D are critical for the analysis.\n",
    "\n",
    "before report\n",
    "the code is\n",
    "print(df.isna().sum())\n",
    "\n",
    "assuming the output is\n",
    "A    100\n",
    "B     10\n",
    "C      5\n",
    "D      0\n",
    "\n",
    "approach:Remove Column A: Since it has too many missing values and is not essential for the analysis.Drop Remaining Rows with Missing Values: For columns B, C, and D.\n",
    "\n",
    "implecation is:# Remove the column with excessive missing values\n",
    "del df['A']\n",
    "cleaned_df = df.dropna()\n",
    "print(cleaned_df.isna().sum())\n",
    "\n",
    "after report:\n",
    "print(cleaned_df.isna().sum())\n",
    "assuming the output is\n",
    "B    0\n",
    "C    0\n",
    "D    0\n",
    "\n",
    "justification: Removing column A ensures that we do not work with data that has too many missing entries, which might skew analysis or increase computational complexity. After removing irrelevant columns, dropping rows with missing values in the critical columns ensures that the data used in analysis is complete and reliable, thus maintaining data integrity and improving the quality of insights derived from the analysis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22ee28e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'col'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py:4441\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4436\u001b[0m             deleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   4437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m deleted:\n\u001b[1;32m   4438\u001b[0m     \u001b[38;5;66;03m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[1;32m   4439\u001b[0m     \u001b[38;5;66;03m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[1;32m   4440\u001b[0m     \u001b[38;5;66;03m# exception:\u001b[39;00m\n\u001b[0;32m-> 4441\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39midelete(loc)\n\u001b[1;32m   4444\u001b[0m \u001b[38;5;66;03m# delete from the caches\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'col'"
     ]
    }
   ],
   "source": [
    "del df['col']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cf5f5",
   "metadata": {},
   "source": [
    "# It's wrong because the name 'col' doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1f0fd",
   "metadata": {},
   "source": [
    "#Summary of Exchanges\n",
    "Introduction to df.describe() and df.shape:\n",
    "df.describe(): Provides summary statistics for numerical columns in a DataFrame, including count, mean, standard deviation, min, quartiles, and max values.\n",
    "df.shape: Returns the dimensions of the DataFrame, indicating the number of rows and columns.\n",
    "Examples of Using df.describe() and df['column'].value_counts():\n",
    "df.describe(): Example usage for obtaining summary statistics for numerical columns.\n",
    "df['column'].value_counts(): Example usage for counting unique values in a categorical column.\n",
    "Handling Missing Data:\n",
    "df.dropna(): Used to remove rows with missing values, useful when you need to analyze data with complete entries.\n",
    "del df['col']: Used to remove columns with excessive missing values or irrelevant columns, simplifying the dataset.\n",
    "Use Cases:\n",
    "Use Case for df.dropna(): Preferred when you need to retain important columns but discard rows with missing values in those columns (e.g., analyzing transactions with available amounts).\n",
    "Use Case for del df['col']: Preferred when a column has too many missing values and is not relevant for analysis (e.g., removing a column with many missing temporary addresses).\n",
    "Importance of Order:\n",
    "Applying del df['col'] before df.dropna() is important if a column with many missing values is irrelevant, to avoid unnecessary operations and retain more useful data.\n",
    "Removing Missing Data:\n",
    "Approach: Remove irrelevant columns with excessive missing values first, then apply df.dropna() to clean the remaining data.\n",
    "Example: Removing column A due to excessive missing values and then dropping rows with missing values in other columns (B, C, D).\n",
    "Error Handling:\n",
    "Issue: Encountered a KeyError when trying to delete a non-existent column.\n",
    "Resolution: Check existing columns with df.columns, ensure the column name exists, and use the correct name for deletion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b69bd",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16c31586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57c394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7d2cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "pclass                                                           \n",
       "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"pclass\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a219f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count       mean        std     min       25%    50%        75%  \\\n",
      "embarked                                                                    \n",
      "C         168.0  59.954144  83.912994  4.0125  13.69795  29.70  78.500025   \n",
      "Q          77.0  13.276030  14.188047  6.7500   7.75000   7.75  15.500000   \n",
      "S         644.0  27.079812  35.887993  0.0000   8.05000  13.00  27.900000   \n",
      "\n",
      "               max  \n",
      "embarked            \n",
      "C         512.3292  \n",
      "Q          90.0000  \n",
      "S         263.0000  \n"
     ]
    }
   ],
   "source": [
    "#a different example from the \"titanic\" data set\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "grouped_describe_fare = df.groupby(\"embarked\")[\"fare\"].describe()\n",
    "print(grouped_describe_fare)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15c427",
   "metadata": {},
   "source": [
    "#Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?\n",
    "\n",
    "Answer:The df.describe() and df.groupby(\"col1\")[\"col2\"].describe() methods offer distinct types of summaries and insights about a DataFrame, especially when addressing missing values.\n",
    "\n",
    "Key Differences\n",
    "\n",
    "df.describe():\n",
    "Purpose: Provides statistical summaries for numerical columns across the entire DataFrame.\n",
    "Count in df.describe(): Shows the number of non-missing (non-NaN) entries in each numerical column. Columns with missing values will have a count lower than the DataFrame's total number of rows. This measure does not apply to categorical columns.\n",
    "Insight: Offers overall descriptive statistics (mean, standard deviation, minimum, maximum, quartiles) for each column, useful for gauging the general data distribution. However, it does not consider variations in data across different groups within the DataFrame.\n",
    "\n",
    "df.groupby(\"col1\")[\"col2\"].describe():\n",
    "Purpose: Gives a statistical summary for a specific column (col2) within each subgroup defined by another column (col1).\n",
    "Count in df.groupby(\"col1\")[\"col2\"].describe(): Indicates the number of non-missing entries in col2 for each col1 subgroup. The analysis is conducted separately for each group, and the count is specific to that group.\n",
    "Insight: Aids in understanding how the distribution of values in a column varies among groups. It reveals if certain groups have more missing values or exhibit different statistical distributions.\n",
    "\n",
    "Fundamental Differences\n",
    "Scope of Analysis:\n",
    "df.describe() provides a comprehensive overview of the data, summarizing the values of columns across the entire DataFrame.\n",
    "df.groupby(\"col1\")[\"col2\"].describe() offers a detailed view, summarizing the values of a column within specific groups determined by another column.\n",
    "Impact of Missing Values:\n",
    "In df.describe(), the count reflects the total present values in each column, not considering how missing values are distributed among groups.\n",
    "In df.groupby(\"col1\")[\"col2\"].describe(), the count shows the non-missing values within each group, which may differ based on the completeness of data in each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0fc94",
   "metadata": {},
   "source": [
    "#example\n",
    "#Without Removing Missing Values,the code is\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df['age'].describe())\n",
    "print(df.groupby(\"pclass\")[\"age\"].describe())\n",
    "\n",
    "#Output for df['age'].describe():\n",
    "\n",
    "count    714.000000\n",
    "mean      29.699118\n",
    "std       14.526497\n",
    "min        0.420000\n",
    "25%       20.125000\n",
    "50%       28.000000\n",
    "75%       38.000000\n",
    "max       80.000000\n",
    "Name: age, dtype: float64\n",
    "\n",
    "#count: 714 non-missing values out of 891 total rows.\n",
    "\n",
    "#Output for df.groupby(\"pclass\")[\"age\"].describe():\n",
    "            count        mean         std   min    25%   50%    75%   max\n",
    "pclass                                                                   \n",
    "1        216.000000  38.233440  14.235776  22.0  30.000  35.0  44.000  80.0\n",
    "2        184.000000  29.877630  14.256279  23.0  22.000  27.0  36.000  70.0\n",
    "3        491.000000  24.734245  15.014139  0.42  17.000  22.0  30.000  80.0\n",
    "#Counts for groups:\n",
    "Class 1: 216 non-missing values.\n",
    "Class 2: 184 non-missing values.\n",
    "Class 3: 491 non-missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478f210",
   "metadata": {},
   "source": [
    "#I showed that i report the error to chatgpt in the following link\n",
    "\n",
    "https://chatgpt.com/share/521a5c8a-b1bc-4117-9fd6-367db5f7ed9e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1124b5b",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
